{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "968b7f40",
   "metadata": {},
   "source": [
    "Utilizo este cuaderno para hacer un seguimiento a la clase y tomar algunas notas. \n",
    "\n",
    "Algo que aprendí es que se crea un venv (virtual environment) \n",
    "\n",
    "SE abre una terminal en VS code y se coloca:$ python -m venv .venv  \n",
    "\n",
    "\n",
    "Se activa el venv con: $ source .venv/bin/activate\n",
    "\n",
    "Esto es lo que se indica para que sirve:\n",
    "\n",
    "A virtual environment (venv) in Python creates an isolated space for a project's dependencies, preventing conflicts with other projects or the system-wide Python installation.​\n",
    "\n",
    "Key Benefits\n",
    "Avoids version conflicts by allowing different package versions per project, such as Django 1.4 in one and 1.6 in another.​\n",
    "\n",
    "Keeps the global Python clean and protects the system from unwanted changes during experimentation.​\n",
    "\n",
    "Enhances portability and reproducibility, making it easy to replicate setups on servers or team machines via files like requirements.txt.​\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e446279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-3-pro-preview\n",
      "models/gemini-3-pro-image-preview\n",
      "models/nano-banana-pro-preview\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-001\n",
      "models/veo-3.0-fast-generate-001\n",
      "models/veo-3.1-generate-preview\n",
      "models/veo-3.1-fast-generate-preview\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure()\n",
    "\n",
    "# List all available models\n",
    "for model in genai.list_models():\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f930f973",
   "metadata": {},
   "source": [
    "Acá el problema que tuve en el que no corria es que el paquete de genai no estaba bien instalado en el venv. Por tanto no podia utilizarlo correctamente. \n",
    "\n",
    "Utilicé gemini para resolver el tema y me di cuenta que no estaba todo instalado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e075676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-lite\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-lite\\nPlease retry in 48.754687238s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-lite'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash-lite', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-lite'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}\n",
      "Please check if your API key is correct and the environment variable is set.\n"
     ]
    }
   ],
   "source": [
    "# el problma que tenia era que no estaba instalando bien las librerias de google. \n",
    "# Me faltaba algo de pip install google-genai\n",
    "# tampoco estaba colocando el nombre de la variable como GEMINI_API_KEY\n",
    "\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv # Only needed if using the .env file method\n",
    "\n",
    "# If using the .env file method, load the variables\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    # The client will automatically use the GEMINI_API_KEY environment variable\n",
    "    llave = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "    client = genai.Client(api_key=llave)\n",
    "    \n",
    "    user_prompt= \"describe en una oracion que es Tarija, Bolivia \"\n",
    "    \n",
    "    # Simple model query\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-lite\",\n",
    "        contents=user_prompt,\n",
    "        config=types.GenerateContentConfig(\n",
    "            temperature=0.3, # lower = more deterministic, higher = more creative\n",
    "            #max_output_tokens=1000, # optional, just an example\n",
    "        ),)\n",
    "    \n",
    "    print(\"--- API Call Successful ---\")\n",
    "    print(response.text)\n",
    "    \n",
    "    # how do you choose the text that comes. \n",
    "    # also how do you choo\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please check if your API key is correct and the environment variable is set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a3d51d",
   "metadata": {},
   "source": [
    "STREAMLIT\n",
    "\n",
    "Para hacer funcionar streamlit, se va a la terminal y se ejecuta lo siguiente:\n",
    "\n",
    "$ streamlit run streamlit_app.py\n",
    "\n",
    "siendo streamlit_app.py la aplicacion en la que estan los comandos streamlit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "950108a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models:\n",
      "- models/embedding-gecko-001 (Supports: embedText, countTextTokens)\n",
      "- models/gemini-2.5-flash (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-2.5-pro (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-2.0-flash-exp (Supports: generateContent, countTokens, bidiGenerateContent)\n",
      "- models/gemini-2.0-flash (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-2.0-flash-001 (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-2.0-flash-exp-image-generation (Supports: generateContent, countTokens, bidiGenerateContent)\n",
      "- models/gemini-2.0-flash-lite-001 (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-2.0-flash-lite (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-2.0-flash-lite-preview-02-05 (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-2.0-flash-lite-preview (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-exp-1206 (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-2.5-flash-preview-tts (Supports: countTokens, generateContent)\n",
      "- models/gemini-2.5-pro-preview-tts (Supports: countTokens, generateContent, batchGenerateContent)\n",
      "- models/gemma-3-1b-it (Supports: generateContent, countTokens)\n",
      "- models/gemma-3-4b-it (Supports: generateContent, countTokens)\n",
      "- models/gemma-3-12b-it (Supports: generateContent, countTokens)\n",
      "- models/gemma-3-27b-it (Supports: generateContent, countTokens)\n",
      "- models/gemma-3n-e4b-it (Supports: generateContent, countTokens)\n",
      "- models/gemma-3n-e2b-it (Supports: generateContent, countTokens)\n",
      "- models/gemini-flash-latest (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-flash-lite-latest (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-pro-latest (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-2.5-flash-lite (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-2.5-flash-image-preview (Supports: generateContent, countTokens, batchGenerateContent)\n",
      "- models/gemini-2.5-flash-image (Supports: generateContent, countTokens, batchGenerateContent)\n",
      "- models/gemini-2.5-flash-preview-09-2025 (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-2.5-flash-lite-preview-09-2025 (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-3-pro-preview (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-3-flash-preview (Supports: generateContent, countTokens, createCachedContent, batchGenerateContent)\n",
      "- models/gemini-3-pro-image-preview (Supports: generateContent, countTokens, batchGenerateContent)\n",
      "- models/nano-banana-pro-preview (Supports: generateContent, countTokens, batchGenerateContent)\n",
      "- models/gemini-robotics-er-1.5-preview (Supports: generateContent, countTokens)\n",
      "- models/gemini-2.5-computer-use-preview-10-2025 (Supports: generateContent, countTokens)\n",
      "- models/deep-research-pro-preview-12-2025 (Supports: generateContent, countTokens)\n",
      "- models/embedding-001 (Supports: embedContent)\n",
      "- models/text-embedding-004 (Supports: embedContent)\n",
      "- models/gemini-embedding-exp-03-07 (Supports: embedContent, countTextTokens, countTokens)\n",
      "- models/gemini-embedding-exp (Supports: embedContent, countTextTokens, countTokens)\n",
      "- models/gemini-embedding-001 (Supports: embedContent, countTextTokens, countTokens, asyncBatchEmbedContent)\n",
      "- models/aqa (Supports: generateAnswer)\n",
      "- models/imagen-4.0-generate-preview-06-06 (Supports: predict)\n",
      "- models/imagen-4.0-ultra-generate-preview-06-06 (Supports: predict)\n",
      "- models/imagen-4.0-generate-001 (Supports: predict)\n",
      "- models/imagen-4.0-ultra-generate-001 (Supports: predict)\n",
      "- models/imagen-4.0-fast-generate-001 (Supports: predict)\n",
      "- models/veo-2.0-generate-001 (Supports: predictLongRunning)\n",
      "- models/veo-3.0-generate-001 (Supports: predictLongRunning)\n",
      "- models/veo-3.0-fast-generate-001 (Supports: predictLongRunning)\n",
      "- models/veo-3.1-generate-preview (Supports: predictLongRunning)\n",
      "- models/veo-3.1-fast-generate-preview (Supports: predictLongRunning)\n",
      "- models/gemini-2.5-flash-native-audio-latest (Supports: countTokens, bidiGenerateContent)\n",
      "- models/gemini-2.5-flash-native-audio-preview-09-2025 (Supports: countTokens, bidiGenerateContent)\n",
      "- models/gemini-2.5-flash-native-audio-preview-12-2025 (Supports: countTokens, bidiGenerateContent)\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv # Only needed if using the .env file method\n",
    "\n",
    "# If using the .env file method, load the variables\n",
    "load_dotenv()\n",
    "client = genai.Client()\n",
    "\n",
    "print(\"Available Models:\")\n",
    "for model in client.models.list():\n",
    "    print(f\"- {model.name} (Supports: {', '.join(model.supported_actions)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38f77c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarija, apodada la \"Perla del Sur\", es una ciudad boliviana vibrante y llena de encanto, ubicada en el sureste del país, conocida por su clima privilegiado y su paisaje de valles fértiles que la convierten en la principal productora de vino y singani de Bolivia. Su centro histórico cautiva con su arquitectura colonial, plazas acogedoras como la 15 de Abril, y su animada vida nocturna y gastronómica, donde destacan sus deliciosos platos regionales y la calidez de su gente. Rodeada de bellezas naturales como la Reserva de Flora y Fauna Tariquía, Tarija ofrece una experiencia única que combina cultura, tradición, aventura y un ambiente relajado, invitando a sus visitantes a disfrutar de sus vinos, su música y su espíritu hospitalario.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. Load the variables from the .env file into the system environment\n",
    "load_dotenv()\n",
    "\n",
    "# 2. Retrieve the key using os.getenv\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# 3. Configure the library with that key\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Use 'gemini-2.5-flash-lite' for the best free-tier experience\n",
    "model = genai.GenerativeModel('gemini-2.5-flash-lite')\n",
    "\n",
    "response = model.generate_content(\"Hablame sobre la ciudad de Tarija-Bolivia en un parrafo\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee6f66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
